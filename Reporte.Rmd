---
title: "Creación de indice con análisis de componentes principales"
author: "Equipo 3"
date: "3/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Objetivo

Se usara análisis de componentes principales para recrear el índice de marginación del Consejo Nacional de la Población. Además se realizaran agrupaciones por el método de clusters jerárquicos con las variables originales y las obtenidas por el método de componentes principales. 

# Índice de marginación CONAPO

Desde 1990 el CONAPO emprendió esfuerzos sistemáticos para construir indicadores con el objetivo de analizar las desventajas sociales de la población e identificar con precisión espacios mayormente marginados, diferenciándolos según su intensidad de carencias, el resultado fue el índice de marginación.

El indice de marginación es un parámetro estadístico que contribuye a la identificación de sectores del país que carecen de oportunidades para su desarrollo y de la capacidad para encontrarlas o generarlas.

## Indicadores socioeconómicos del índice de marginación

- Educación:

    - Porcentaje de población analfabeta
    
    - Porcentaje de población sin primaria completa
    
- Vivienda:

    - Porcentaje de ocupantes en viviendas sin agua entubada
    
    - Porcentaje de ocupantes en viviendas sin drenaje ni servicio sanitario exclusivo
    
    - Porcentaje de ocupantes en viviendas sin drenaje ni excusado

    - Porcentaje de ocupantes en viviendas con algún nivel de hacinamiento
    
    - Porcentaje de ocupantes en viviendas sin energía eléctrica
    
    - Porcentaje de ocupantes en viviendas con piso de tierra
    
- Distribución de la población:

    - Porcentaje de población en localidades con menos de 5,000 habitantes
    
- Ingresos:

    - Porcentaje de población ocupada con ingresos de hasta dos salarios mínimos
    

# Análisis de componentes principales

## Definición y origen de los componentes principales

Sea $x$ un vector de $p$ variables de donde se desea estudiar la estructura de las covarianzas o correlaciones entre las variables.

El análisis de componentes principales se enfoca en las varianzas de las variables, aunque  no ignora las correlaciones ni covarianzas de estas. El primer paso es obtener una función lineal de la forma $\alpha_{1}^{'}x$ de los elementos de $x$ que explique la varianza máxima, donde $\alpha_1$ es un vector de $p$ constantes $\alpha_{11},\alpha_{12},...,\alpha_{1p}$, es decir:

$$\alpha^{'}{1}x = \alpha{11}x_{1} + \alpha_{12}x_{2} + ...  + \alpha_{1p}x_{p} = \sum_{i=1}^{p} \alpha_{1j}x_{j},$$

Después se debe de obtener otra función lineal $\alpha^{'}{2}x$ no correlacionada con la función $\alpha{1}^{'}x$ que también explique la máxima varianza posible. Así, sucesivamente se irán obteniendo estas funciones lineales hasta obtener la k-ésima función lineal $\alpha^{'}{k}x$ que al igual que las $k-1$ funciones lineales obtenidas anteriormente, que explique la máxima varianza posible, siendo ésta no correlacionada con $\alpha^{'}{1}x,\alpha^{'}{2}x,...\alpha^{'}{k-1}x$. La $k$-ésima función corresponde al $k$-ésimo componente principal. Se pueden encontrar hasta $p$ componentes principales pero se desea, en general, que la máxima varianza se encunetre en $m$ componentes componentes principales siendo $m \leq p$. El caso más simple es cuando se tienen dos componentes principales, pues las observaciones puedes ser visualizadas en un plano. Cuando se tienen más componentes principales, la visualización de éstos se dificulta. A lo más se pueden visualizar claramente hasta 3 dimensiones, es decir, hasta 3 componentes. Cuando hay más se podrían visualizar planos de nivel pero se perdería la interpretación

Ya definidos los componentes principales, debemos saber como encontrarlos. Consideremos que el vector de variables aleatorias $X$ tiene matriz de covarianzas $\Sigma$ conocida. Esta matriz, cuyo $(i,j)$-ésimo elemento corresponde a la covarianza entre los elementos $i$ y $j$ de $X$ cuando $i\neq j$, cuando $i=j$ el elemento $(i,j) = (i,i)$ corresponde a la varianza. Cuando $\Sigma$ es desconocida, se reemplaza por la matriz $S$.
Para $k=1,2,...,p$ el $k$-ésimo componente principal se define de la forma $z_k = \alpha^{'}_{k}x$, donde $\alpha_k$ es el eigenvector o vector propio de $\Sigma$ correspondinete al $k$-ésimo eigenvalor o valor propio mas grande $\lambda_k$. 

## Propiedades de los componentes principales y sus implicaciones

Sea $z$ el vector cuyo $k$-ésimo elemento es $z_k$ correspondiente al $k$-ésimo componente principal para $k=1,2,...,p$ entonces

$$z=A'x,$$

en donde A es la matriz ortogonal cuya $k$-ésima columna, $\alpha_k$, es el $k$-ésimo vector propio de $\Sigma$. Así, los componentes principales son definidos de una transformación lineal ortonormal de $X$.

## ¿Cuántos componentes principales seleccionar?

En esta sección se presentarán las reglas para decidir con cuántos componentes principales se deberían conservar para retener la mayor varianza posible en $x$ (o en las variables estandarizadas $x^*$ en el caso de estudiar componentes principales con la matriz de correlación).

### Porcentaje acumulado de la varianza total

El criterio más obvio para seleccionar el número de componentes principales es seleccionando el porcentaje acumulado de la varianza total. Normalmente se desea que los componentes principales seleccionados contribuyan entre $80\%$ y $90\%$. El número requerido de componentes principales es el valor más pequeño $m$ para el cual este porcentaje se ha excedido. Este criterio es válido para la matriz de covarianza y correlación.

### Valores propios / Varianzas

Como se ha mencionado anteriormente, los valores propios miden la cantidad de varianza retenida por cada componente principal. Los valores propios son grandes para los primeros componentes principales y pequeños para los componentes subsecuentes. Esto es debido a que los primeros componentes corresponden a las direcciones con la máxima varianza en el conjunto de datos.

Los valores propios pueden se usados para determinar el número de componentes principales:

- Un valor propio $>1$ indica que el componente principal considera más varianza que la que considera la variable original estandarizada. Esto es utilizado como punto de corte para retener los componentes principales cuyos valores propios sean mayor a 1. Esto es cierto solamente cuando los datos están estandarizados.

- También se puede obtener el número de componentes principales a trabajar seleccionando a aquellos que contengan un cierto porcentaje de varianza total. Por ejemplo, si el usuario está dispuesto a trabajar con el $80\%$ de varianza total explicada, entonces se utilizan los componentes que logren ese porcentaje.

Desafortunadamente no hay forma objetiva para decidir cuántos componentes principales son suficientes. Esto depende de cada conjunto de datos con el que se esté trabajando. En la práctica, se tiende a analizar los primeros componentes principales para encontrar patrones interesantes en los datos.

### Estandarización de los datos

En el análisis de componentes principales las variables se suelen escalar (estandarizar). Esto es recomendable cuando las variables son medidas en diferentes escalas, si no se realiza la estandarización, los resultados del análisis se verán afectados. 
El objetivo es hacer las variables comparables. Generalmente las variables se estandarizan para que éstas cuenten con desviación estándar 1 y media cero. También se recomienda escalar los datos cuando la media y desviación estándar de las variables es muy diferente. 

Cuando se escalan las variables, éstas se transforman de la siguiente manera:

$$\frac{x_i-media(x)}{desv(x)},$$

# Método de Rotaciones de Jacobi para matrices simétricas

Este método produce una secuencia de transformaciones ortogonales de la forma $J_k^TAJ_k$ con el objetivo de hacer “más diagonal” a la matriz $A \in \mathbb{R}^{n \times n}$.




# Implementación

# Resultados 

# Presentación 

# Referencias

- Kassambara, Alboukadel (2017)  Practical Guide To Principal Component Methods in R: PCA, M (CA), FAMD, MFA, HCPC, factoextra. Volumen 2. STHDA.

- I.T. Jolliffe (2002) Principal Component
Analysis. Second Edition. Volumen 2. Springer.

- CONAPO (2010) Índice de marginación por Entidad Federativa. Consejo Nacional de Población México, DF.

- [Notas del curso](https://itam-ds.github.io/analisis-numerico-computo-cientifico/II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html)

